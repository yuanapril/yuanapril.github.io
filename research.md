## Publications

---

<div class="publication-item">
  <div class="pub-image">
    <img src="imgs/ipad.gif" alt="ST-VAD Teaser">
    <div class="pub-tag">ICML 2026</div>
  </div>
  <div class="pub-content">
    <h3>ST-VAD: Spatial-Temporal Mental Modeling for Industrial Video Anomaly Detection via Object-Centric Reasoning</h3>
    <p class="pub-authors"><strong>Mei Yuan</strong>, Yang Liu, Min Xu</p>
    <p class="pub-venue">Submitted to ICML 2026</p>
    <div class="pub-links">
      <a href="#" class="pub-link">ğŸ“„ Paper</a>
      <a href="#" class="pub-link">ğŸ“Š Project</a>
    </div>
    <details class="pub-tldr-collapsible">
      <summary>
        <span class="tldr-label">TL;DR:</span>
        <span class="tldr-text">A VLM-based reasoning framework that elevates video anomaly detection from pattern matching to cognitive-level understanding. By simulating human spatial perception and representing scene dynamics via object-centric state graphs, our approach achieves state-of-the-art performance on industrial benchmarks, pioneering explainable anomaly detection for robotic laboratories.</span>
      </summary>
    </details>
  </div>
</div>

---

<div class="publication-item">
  <div class="pub-image">
    <img src="imgs/tstar.png" alt="Time-STaR Framework">
    <div class="pub-tag">ICML 2026</div>
  </div>
  <div class="pub-content">
    <h3>Time-STaR: Self-Taught Reasoners Augmented with Tools for Reliable Time Series Analysis</h3>
    <p class="pub-venue">Submitted to ICML 2026</p>
    <div class="pub-links">
      <a href="#" class="pub-link">ğŸ“„ Paper</a>
      <a href="#" class="pub-link">ğŸ’» Code</a>
    </div>
    <details class="pub-tldr-collapsible">
      <summary>
        <span class="tldr-label">TL;DR:</span>
        <span class="tldr-text">A reasoning-centric framework that repurposes LLMs for time series forecasting. By curating the Time-STaR-CoTT dataset and implementing GRPO-style reinforcement learning, we enable models to identify causal relationships, detect regime changes, and generate interpretable forecastsâ€”achieving state-of-the-art results across weather, traffic, and finance domains.</span>
      </summary>
    </details>
  </div>
</div>

---

<div class="publication-item">
  <div class="pub-image">
    <img src="imgs/speakout.png" alt="Pronunciation Coaching System">
    <div class="pub-tag">CHI 2026</div>
  </div>
  <div class="pub-content">
    <h3>Guiding Grasp and Growth: Multi-Modal Detection and Feedback on Accented Mispronunciation</h3>
    <p class="pub-authors"><strong>Mei Yuan</strong>, Boting Li</p>
    <p class="pub-venue">Submitted to CHI 2026</p>
    <div class="pub-links">
      <a href="https://drive.google.com/file/d/1Cld1n7yeURCJH_tsa8Z_pG_sF3j9kN73/view?usp=drive_link" class="pub-link">ğŸ“„ Paper</a>
      <a href="#" class="pub-link">ğŸ¯ Demo</a>
    </div>
    <details class="pub-tldr-collapsible">
      <summary>
        <span class="tldr-label">TL;DR:</span>
        <span class="tldr-text">An interactive text-vision-audio pronunciation coaching system combining LLM-powered assessment, Neural TTS exemplars, and viseme animations. Validated with 82 students showing 90%+ satisfaction, the system was adopted as an intelligent teaching assistant in a graduate-level English course at Peking University.</span>
      </summary>
    </details>
  </div>
</div>

---

<div class="publication-item">
  <div class="pub-image">
    <img src="imgs/prformer.jpg" alt="PRformer Architecture">
    <div class="pub-tag">IJCNN 2026</div>
  </div>
  <div class="pub-content">
    <h3>PRformer: Prefix Reprogramming Transformers for Long-Term Series Forecasting</h3>
    <p class="pub-authors"><strong>Mei Yuan</strong>, Hongcheng Guo</p>
    <p class="pub-venue">Submitted to IJCNN 2026</p>
    <div class="pub-links">
      <a href="#" class="pub-link">ğŸ“„ Paper</a>
      <a href="#" class="pub-link">ğŸ’» Code</a>
    </div>
    <details class="pub-tldr-collapsible">
      <summary>
        <span class="tldr-label">TL;DR:</span>
        <span class="tldr-text">A novel approach for long-term time-series forecasting through Prefix Reprogramming with noise-based prefixes, FFT-Attention for periodic patterns, and Average Decomposition for seasonal-trend separationâ€”avoiding information bottlenecks common in traditional Transformer architectures.</span>
      </summary>
    </details>
  </div>
</div>

---

<div class="publication-item">
  <div class="pub-image">
    <img src="imgs/vst.png" alt="DiffuVST Visual Storytelling">
    <div class="pub-tag">EMNLP 2023</div>
  </div>
  <div class="pub-content">
    <h3>DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models</h3>
    <p class="pub-authors">Shengguang Wu, <strong>Mei Yuan</strong>, Qi Su</p>
    <p class="pub-venue">Findings of EMNLP 2023</p>
    <div class="pub-links">
      <a href="https://arxiv.org/pdf/2312.07066v1" class="pub-link">ğŸ“„ Paper</a>
      <a href="#" class="pub-link">ğŸŒ Project</a>
    </div>
    <details class="pub-tldr-collapsible">
      <summary>
        <span class="tldr-label">TL;DR:</span>
        <span class="tldr-text">A non-autoregressive DiffusionLM-based storytelling model that generates coherent narratives around visual sequences. Trained with weighted conditions on global vision-language history, DiffuVST achieves superior performance with 10Ã— faster inference than autoregressive models.</span>
      </summary>
    </details>
  </div>
</div>

---

<div class="publication-item">
  <div class="pub-image">
    <img src="imgs/reid.png" alt="Person Re-identification">
    <div class="pub-tag">ACM MM 2022</div>
  </div>
  <div class="pub-content">
    <h3>A Person Re-identification Approach Focusing on the Occlusion Problem and Ranking Optimization</h3>
    <p class="pub-authors">Wenkai Zheng, <strong>Mei Yuan</strong></p>
    <p class="pub-venue">ACM Multimedia 2022 (MMSports Workshop)</p>
    <div class="pub-links">
      <a href="https://dl.acm.org/doi/abs/10.1145/3552437.3555692" class="pub-link">ğŸ“„ Paper</a>
      <a href="#" class="pub-link">ğŸ† 2nd Place</a>
    </div>
    <details class="pub-tldr-collapsible">
      <summary>
        <span class="tldr-label">TL;DR:</span>
        <span class="tldr-text">A robust person re-identification method addressing occlusion challenges through dual-branch Vision Transformer with jigsaw patch modules and innovative ranking optimization. Achieved 98.38% mAP and 99.57% rank-1 accuracy, winning second place in the DeepSportRadar Player REID Challenge.</span>
      </summary>
    </details>
  </div>
</div>

---

### Also see [Google Scholar](https://scholar.google.com/citations?user=q4kZ8WMAAAAJ&hl=en) for the complete list.